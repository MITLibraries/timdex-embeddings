# The CD pipeline for multiple, parallel builds

This application has a unique CD pipeline for pushing container images to AWS. All of our other applications will push either an AMD64-based image or an ARM64-based image to the ECR Repository while this one expects to build both.

This application is destined to run in a Compute Environment in AWS Batch and, depending on the data to be processed, the application might run better in an environment that has a GPU or it might run better in an environment without a GPU. (By "better" we mean both faster and at a lower cost. See [Addendum: Use AWS Batch as Compute for Embeddings](https://mitlibraries.atlassian.net/wiki/spaces/D/pages/4832493614/Engineering+Plan+Record+Embeddings+ETL#Addendum%3A-Use-AWS-Batch-as-Compute-for-Embeddings) for more details.)

## Two Dockerfiles

We separate the two builds by leveraging two different Dockerfiles:

* `Dockerfile-gpu`: The Dockerfile that defines the build for any GPU-enabled containers
* `Dockerfile-cpu`: The Dockerfile that defines the build for containers that will not use GPUs

At this time, AWS Batch only supports the `amd64` architecture for AWS Batch compute environments that leverage GPUs. Otherwise, for runs of this application that do not require GPUs, the `arm64` architecture is less expensive and more efficient.

## CPU Architecture

We will stick with a single `.aws-architecture` file to manage the CPU architecture choice, but we will format it as a simple list of key/value pairs and leverage `jq` to parse the information in our `make` commands and GitHub workflows. The file will look like

```json
{
    "gpu": "linux/<arch>",
    "cpu": "linux/<arch>"
}
```

Where `<arch>` is either `amd64` or `arm64`.

## Makefile configuration

There are a collection of targets in the Makefile for generating Docker images locally and pushing those local builds to the ECR Repository in the Dev1 AWS Account. The tags generated by running these targets will include the work `make` so that it is clear in the AWS Console that the image came from a developer, not from GitHub Actions.

## GitHub Actions

There are three GitHub Actions workflows for automated build+deploy to AWS. These do **NOT** depend on the `Makefile` targets at all. While the triggers follow our typical GitHub-flow, the actual build process is different from the rest of our application respositories

### Dev Workflow

**Note**: This workflow runs when a PR is opened or when an open PR is updated, _unless that PR is triggered by `depdendabot`_.

1. There is an initial job that runs and parses the `.aws-architecture` file and generates outputs that will drive the next phase.
1. The second phase of the workflow is a matrix strategy that will kick off two runners, one for each build. The runner is picked to match the CPU architecture of the requested build. That is, if the `gpu` key in the `.aws-architecture` file specifies `linux/amd64`, then the runner for the `gpu` container will be an `amd64`-based runner. If the `cpu` key in the `.aws-architecture` file specifies `linux/arm64` then the `cpu` container will be an `arm64`-based runner. This way, when Docker runs, it is running on the same architecture as the container it is trying to build.

### Stage Workflow

The Stage workflow is the same as the Dev workflow, only the trigger is different (it runs on `push` instead of `pull_request`).

### Prod Workflow

Similar to our shared workflows, the Prod workflow will run on a tagged release on the `main` branch. Different from our shared workflows, the workflow will first run a job to capture the CPU architecture information from the `.aws-architecture` file so that the subsequent job can find the correct tags on the containers in the Stage ECR Reository to push over to Prod.

**Job 1**: Process the `.aws-architecture` file to capture the CPU architectures for the GPU containers and the CPU containers.

**Job 2**: Use the output of **Job 1** to generate a matrix to run parallel jobs to pull containers from Stage, re-tag them for Prod, and then push them to Prod. Just like our shared workflows, the very first step is to check whether the commit SHA on `main` (where the tagged release is being applied) matches the commit SHA that was tagged onto the container in the Stage-Workloads ECR Repository.
